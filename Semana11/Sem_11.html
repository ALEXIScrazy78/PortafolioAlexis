<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Semana 11</title>
    <link rel="stylesheet" href="Sem_11.css">
</head>
<body>

    <button id="scrollToTopBtn" class="btn" style="display: none; position: fixed; bottom: 20px; right: 20px; z-index: 99;">
        ⬆️ Subir
    </button>
    
    <nav class="navbar">
        <div class="logo">
            <div class="basketball-decoration"></div>
            <span>Semana 11</span>
        </div>
        <ul class="nav-links">
            <li><a href="../index.html">Inicio</a></li>
            <li><a href="../index.html#about">Sobre Mí</a></li>
            <li><a href="../index.html#weeks">Semanas</a></li>
            <li><a href="../index.html#projects">Proyectos</a></li>
        </ul>
    </nav>

    <header class="page-header">
        <h1>Semana 11: TrackEd - Herramienta de Seguimiento de Emociones para Plataformas de E-Meeting</h1>
        <h3>¿Qué hemos aprendido?</h3><br>
        <p>
            En esta semana, analizamos el artículo científico sobre TrackEd, 
            una herramienta innovadora que utiliza inteligencia artificial y redes 
            neuronales convolucionales (CNN) para rastrear emociones en plataformas 
            de reuniones virtuales. Aprendimos sobre su arquitectura, metodología de
            desarrollo, y cómo aborda los desafíos de la educación en línea, especialmente
            la falta de retroalimentación emocional en tiempo real. También exploramos 
            conceptos clave como computación afectiva, procesamiento de imágenes y métricas
            de evaluación de modelos de aprendizaje profundo.
        </p>
    </header>

    <div class="container">
        <div class="week-content">
            <div class="week-info">
                <div class="info-card">
                    <h3>Objetivos de Aprendizaje</h3>
                    <ul>
                        <li>Comprender el funcionamiento de TrackEd y su aplicación</li>
                        <li>Analizar la arquitectura del software, Frame Grabber y Emotion Detector</li>
                        <li>Evaluar las métricas de rendimiento del modelo de clasificación de emociones</li>
                        <li>Explorar el impacto potencial de la herramienta</li>
                        <li>Familiarizarnos con tecnologías como OpenCV, Keras, TensorFlow y técnicas de aumento de datos</li>
                    </ul>
                </div>
                <div class="info-card">
                    <h3>Tecnologías Utilizadas</h3>
                    <ul>
                        <li><b>Frame Grabber: </b>OpenCV (detección de rostros con cascadas de Haar)</li>
                        <li><b>Emotion Detector: </b>Red neuronal convolucional (CNN) con capas convolucionales, Batch Normalization, ReLu y Dropout</li>
                        <li><b>Entrenamiento del modelo: </b>Dataset de 40,254 imágenes (7 emociones), aumentado con ImageDataGenerator de Keras.</li>
                        <li><b>Optimización: </b>Adam con tasa de aprendizaje inicial de 0.001 y mecanismo de decay</li>
                        <li><b>Evaluación: </b> cikit-Learn para métricas (precisión, recall, ROC curve)</li>
                    </ul>
                </div>
            </div>

           <div class="image-container">
                <img src="imgsem11.jpg" alt="Imagen de la semana" class="imgsem1">
            </div>q 

            <h2 class="section-title">¿Que se hizo?</h2>         

            <div class="ejercicios-container">
              
                <div class="ejercicio-item">
                    <h3>1. Composición del arículo</h3>
                        <ul class="listar"
                        >
                            <li style="text-align: justify;"><b>Análisis del artículo científico:</b> Traducción y síntesis de las secciones clave: introducción, metodología, arquitectura y resultados.</li>
                            <li style="text-align: justify;"><b>Exposición: </b>Demostración de las métricas de evaluación (tabla de precisión por emoción) y limitaciones del modelo (ej. bajo rendimiento en miedo y enojo).</li>
                            <li style="text-align: justify;"><b>Impacto potencia</b>Beneficios para docentes (adaptación de clases), instituciones (retención estudiantil) y plataformas virtuales (experiencia personalizada).</li><br>
                        </ul>
                    <div class="exercise-preview">
                        <img src="imgsem11_1.jpg" alt="Imagen de la semana" class="imgsem1">
                    </div>
                </div>
            </div>

            <h2 class="section-title">Ttabajo grupal</h2>   
            <div class="ejercicios-container">
              
                <div class="ejercicio-item">
                    <h3>Despliegue de la aplicación web mediante Tokens</h3>
                        <ul class="listar">
                            <li style="text-align: justify;">
                            Se realizó una presentación en Canva que resumió 
                            el análisis del artículo científico sobre TrackEd, destacando su arquitectura,
                            metodología, resultados y potencial impacto en la educación virtual. Además, 
                            se compartieron los recursos clave utilizados: el repositorio de GitHub con el
                            código fuente, el archivo PPT de la exposición y el artículo original en PDF,
                            los cuales están disponibles para consulta y profundización en el tema.
                             </li><br>
                        </ul>
                    <div class="exercise-preview">
                        <a href="https://www.sciencedirect.com/science/article/pii/S2665963823000970" class="btn">Artículo completo</a>
                        <a href="https://github.com/SoftwareImpacts/SIMPAC-2023-299" class="btn">Repositorio en Github</a>
                        <a href="https://www.canva.com/design/DAGqhsNdnyo/6Li46F9gGQbJW_7y7-3W2w/edit?utm_content=DAGqhsNdnyo&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton" class="btn">Presentación en Canva</a>
                    </div>
                </div>
            </div>
            
            <h2 class="section-title">Conclusión</h2>
            <div class="reflection">
                <p>El análisis de TrackEd evidenció cómo la computación afectiva puede revolucionar la educación 
                    en línea al proporcionar retroalimentación emocional en tiempo real. La herramienta, aunque
                    con margen de mejora en precisión, demuestra que la IA puede cerrar la brecha entre 
                    la interacción presencial y virtual. Su integración en plataformas educativas podría 
                    optimizar la enseñanza basada en datos emocionales, beneficiando a estudiantes, docentes 
                    e instituciones.
                </p>
            </div>

            <h2 class="section-title">Reflexión </h2>
            <div class="reflection">
                <p>Este proyecto reforzó la importancia de traducir investigaciones académicas
                    en soluciones prácticas. TrackEd resalta cómo los modelos de deep learning 
                    pueden aplicarse a problemas reales, como la falta de engagement en aulas 
                    virtuales. Sin embargo, también surgieron preguntas éticas: ¿cómo garantizar 
                    la privacidad de los datos emocionales? ¿Qué sesgos podrían existir en el dataset? 
                    Futuras iteraciones podrían explorar estos desafíos y mejorar la precisión con 
                    datasets más equilibrados.
                </p>
            </div>


            <h2 class="section-title">Recursos Utilizados</h2>
            <div class="resources">
                <ul>
                    <li class="recurso-link">
                        <a href="https://www.sciencedirect.com/science/article/pii/S2665963823000970" class="recurso-btn">
                          <i class="fab fa-github"></i> Artículo original
                        </a>
                        <span class="recurso-desc">- TrackEd: An emotion tracking tool for e-meeting platforms (Software Impacts, 2023)</span>
                    </li>

                    <li class="recurso-link">
                        <a href="https://github.com/SoftwareImpacts/SIMPAC-2023-299/tree/main/tracked_train_files" class="recurso-btn">
                          <i class="fab fa-github"></i> Dataset
                        </a>
                        <span class="recurso-desc">- Facial Expression Classification Dataset (Mendeley Data)</span>
                    </li>

                    <li class="recurso-link">
                        <a href="https://github.com/SoftwareImpacts/SIMPAC-2023-299" class="recurso-btn">
                          <i class="fab fa-github"></i> Repositorio
                        </a>
                        <span class="recurso-desc">- GitHub - TrackEd</span>
                    </li>
                </ul>
            </div>



            <div class="navigation-buttons">
                <a href="../Semana10/Sem_10.html" class="btn">← Semana Anterior</a>
                <a href="../Semana12/Sem_12.html" class="btn">Semana Siguiente →</a>
                </div>
        </div>
    </div>

    <footer>
        <div class="basketball-decoration"></div>
        <p>&copy; 2025 | Todos los derechos reservados </p>
        <p>Desarrollado por Castro Casas Alexis</p>
    </footer>

    <script src="Sem_11.js"></script>
</body>
</html>